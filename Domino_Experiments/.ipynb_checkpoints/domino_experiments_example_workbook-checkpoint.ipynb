{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments (MLflow) Tutorial\n",
    "\n",
    "This `domino_experiments_example_workbook.ipynb` Jupyter notebook shows an example of how you can use the Experiments feature to train and compare models.\n",
    "\n",
    "In this tutorial, you will:\n",
    "* train several support vector machine models to classify handwritten digits\n",
    "* create an experiment using MLflow\n",
    "* create runs within an experiment using MLflow\n",
    "* persist parameters, metrics, and artifacts that ensure reproducibility and enable visual comparison of models\n",
    "\n",
    "## Attribution\n",
    "* Some code is adapted from [sklearn's tutorial for \"Recognizing hand-written digits\"](https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html)\n",
    "* Inspriation for the structure of the experiment and runs taken from [mlflow's sklearn_elasticnet_wine example](https://github.com/mlflow/mlflow/blob/master/examples/sklearn_elasticnet_wine/train.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License for code in this notebook: BSD 3 clause\n",
    "# import everything we'll need for the rest of the notebook\n",
    "import os\n",
    "from copy import copy\n",
    "from itertools import product\n",
    "import pprint\n",
    "import shutil\n",
    "import time\n",
    "from typing import Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from sklearn import datasets, metrics, svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment id: 60\n",
      "Experiment name: example-svm-digit-classifier-petelowth-1727098283.4815376\n"
     ]
    }
   ],
   "source": [
    "# create an experiment in MLflow\n",
    "\n",
    "# we'll make the name unique in the project by appending a timestamp so that you and other users can run this cell more than once.\n",
    "timestamp = time.time()\n",
    "username = os.environ['DOMINO_STARTING_USERNAME']\n",
    "experiment_name = f\"example-svm-digit-classifier-{username}-{timestamp}\"\n",
    "# below, we'll use the returned experiment_id in calls to mlflow.start_run() to add data to the experiment.\n",
    "experiment_id = mlflow.create_experiment(experiment_name)\n",
    "print(f\"Experiment id: {experiment_id}\")\n",
    "print(f\"Experiment name: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "\n",
    "# this dataset has handwritten roman numerals represented as 8x8 pixel grayscale images\n",
    "digits = datasets.load_digits()\n",
    "# flatten each 2-D array of grayscale values from shape (8, 8) into shape (64,)\n",
    "# data will have shape (n_samples = number of images, n_features = total number of pixels in each image)\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "# split the data into train and test subsets\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    data, digits.target, test_size=0.20, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that uses an SVM to classify the digits while recording relevant info as an MLflow run \n",
    "# within the given experiment.\n",
    "def create_run_svm_classify(\n",
    "    experiment_id: str,\n",
    "    train_x: np.ndarray,\n",
    "    train_y: np.ndarray,\n",
    "    test_x: np.ndarray,\n",
    "    test_y: np.ndarray,\n",
    "    random_seed: int,\n",
    "    svc_param_kwargs: Dict = None,\n",
    "    run_name: str = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Record an MLflow run for experiment_id.\n",
    "    Trains a Support Vector Machine classifier using train_x, train_y, and the given svm_param_kwargs.\n",
    "    Then, predicts using test_x and test_y and logs params, metrics, artifacts, and model to MLflow.\n",
    "\n",
    "    :param str experiment_id: id of the MLflow experiment in which to record the run\n",
    "    :param np.ndarray train_x: x values for the training data\n",
    "    :param np.ndarray train_y: y values for the training data\n",
    "    :param np.ndarray test_x: x values for the test data\n",
    "    :param np.ndarray test_y: y values for the test data\n",
    "    :param int random_seed: used to set the random seed for all random number generators in this run \n",
    "        (e.g. numpy seed, sklearn model random state, etc.)\n",
    "    :param Dict svc_param_kwargs: kwargs to use when creating the sklearn.svm.SVC (e.g. C, kernel, etc.)\n",
    "    :param str run_name: name for the run in MLflow. If None, MLflow will generate a random name\n",
    "    \"\"\"\n",
    "    if random_seed is None:\n",
    "        random_seed = 42\n",
    "    svc_param_kwargs = svc_param_kwargs or {}\n",
    "    svc_param_kwargs[\"random_state\"] = random_seed\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "    # passing experiment_id tells MLflow to associate the run data with the correct experiment.\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=run_name) as run:\n",
    "        mlflow.set_tag(\"random_seed\", str(random_seed))        \n",
    "        mlflow.set_tag(\"quality\", \"an excellent experiment\")\n",
    "        if run_name is None:\n",
    "            run_name = run.info.run_name\n",
    "        pretty_params = pprint.pformat(svc_param_kwargs, width=1, indent=2)\n",
    "        print(\"******************************************\")\n",
    "        print(\"******************************************\")\n",
    "        print(f\"Starting run {run_name} in experiment {experiment_id} with SVC params:\")\n",
    "        print(f\"{pretty_params}\")\n",
    "\n",
    "        print(\"Initializing model...\")\n",
    "        classifier = svm.SVC(**svc_param_kwargs)\n",
    "\n",
    "        print(\"Training model...\")\n",
    "        classifier.fit(train_x, train_y)\n",
    "\n",
    "        print(\"Predicting using trained model...\")\n",
    "        predicted = classifier.predict(test_x)\n",
    "        prediction_report_str = metrics.classification_report(test_y, predicted, digits=3, output_dict=False)\n",
    "        prediction_report_dict = metrics.classification_report(test_y, predicted, output_dict=True)\n",
    "\n",
    "        # print some info about the run and also save as file for an MLflow artifact\n",
    "        print(\"Finished predictions.\")\n",
    "        run_overview = (\n",
    "            f\"Run: {run_name}\\n\"\n",
    "            f\"Random seed: {random_seed}\\n\"\n",
    "            \"Classifier type: sklearn.svm.SVC\\n\"\n",
    "            \"Specified classifier params:\\n\"\n",
    "            f\"{pretty_params}\"\n",
    "            \"\\n\"\n",
    "            \"Classification report:\\n\"\n",
    "            f\"{prediction_report_str}\\n\"\n",
    "        )\n",
    "        print(f\"{run_overview}\")\n",
    "        run_overview_file_name = \"run_overview.txt\"\n",
    "        with open(run_overview_file_name, \"w\") as f:\n",
    "            f.write(run_overview)\n",
    "\n",
    "        # visualize model performance and save visualization for an MLflow artifact\n",
    "        disp = metrics.ConfusionMatrixDisplay.from_predictions(test_y, predicted)\n",
    "        disp.figure_.suptitle(f\"Confusion Matrix - Run {run_name}\")\n",
    "        confusion_matrix_file_name = f\"confusion_matrix_run_{run_name}.png\"\n",
    "        plt.savefig(confusion_matrix_file_name)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Recording run params, metrics, and artifacts to MLflow...\")\n",
    "        # record notable sklearn model params and performance metrics.\n",
    "        # this enables visual comparison via the Experiments UI.\n",
    "        for param, val in svc_param_kwargs.items():\n",
    "            mlflow.log_param(param, val)\n",
    "        # record metrics for each individual digit as well as overall averages\n",
    "        for metric in (\"precision\", \"recall\", \"f1-score\"):\n",
    "            for digit in {str(num) for num in range(0, 10)}:\n",
    "                mlflow.log_metric(f\"{metric}_{digit}\", prediction_report_dict[digit][metric])\n",
    "            for avg_type in (\"macro\", \"weighted\"):\n",
    "                mlflow.log_metric(f\"{metric}_{avg_type}_avg\", prediction_report_dict[f\"{avg_type} avg\"][metric])\n",
    "        mlflow.log_metric(\"overall_accuracy\", prediction_report_dict[\"accuracy\"])\n",
    "\n",
    "        # record the data for reproducibility\n",
    "        data_dir_name = \"run_data\"\n",
    "        os.mkdir(data_dir_name)\n",
    "        for data, data_name in ((train_x, \"train_x\"), (train_y, \"train_y\"), (test_x, \"test_x\"), (test_y, \"test_y\")):\n",
    "            with open(os.path.join(data_dir_name, f\"{data_name}.csv\"), \"w\") as data_file:\n",
    "                np.savetxt(data_file, data, delimiter=\",\")\n",
    "        mlflow.log_artifact(data_dir_name)\n",
    "        shutil.rmtree(data_dir_name)\n",
    "\n",
    "        # record human-readable/interpretable overview and figures\n",
    "        mlflow.log_artifact(run_overview_file_name)\n",
    "        mlflow.log_artifact(confusion_matrix_file_name)\n",
    "\n",
    "        # record the trained sklearn model\n",
    "        mlflow.sklearn.log_model(classifier, \"model\")\n",
    "        print(\"Finishing recording.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Run with UUID e1cda022c7334b7199cf14e90c5c4142 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m      6\u001b[0m svc_param_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m: regularization,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m: gamma,\n\u001b[1;32m     10\u001b[0m }\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# each call creates a \"run\" in MLflow and records metrics/artifacts about that run\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mcreate_run_svm_classify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvc_param_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msvc_param_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mregularization\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_gamma_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgamma\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 38\u001b[0m, in \u001b[0;36mcreate_run_svm_classify\u001b[0;34m(experiment_id, train_x, train_y, test_x, test_y, random_seed, svc_param_kwargs, run_name)\u001b[0m\n\u001b[1;32m     35\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_tag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquality\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man excellent experiment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# passing experiment_id tells MLflow to associate the run data with the correct experiment.\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m run:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m run_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m         run_name \u001b[38;5;241m=\u001b[39m run\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_name\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/tracking/fluent.py:306\u001b[0m, in \u001b[0;36mstart_run\u001b[0;34m(run_id, experiment_id, run_name, nested, tags, description, log_system_metrics)\u001b[0m\n\u001b[1;32m    304\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(experiment_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(experiment_id, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_active_run_stack) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nested:\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    307\u001b[0m         (\n\u001b[1;32m    308\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun with UUID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is already active. To start a new run, first end the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    309\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent run with mlflow.end_run(). To start a nested \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    310\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun, call start_run with nested=True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    311\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(_active_run_stack[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id)\n\u001b[1;32m    312\u001b[0m     )\n\u001b[1;32m    313\u001b[0m client \u001b[38;5;241m=\u001b[39m MlflowClient()\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_id:\n",
      "\u001b[0;31mException\u001b[0m: Run with UUID e1cda022c7334b7199cf14e90c5c4142 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
     ]
    }
   ],
   "source": [
    "# perform a hyperparam sweep to find the best regularization and gamma for an SVC with a radial basis function kernel\n",
    "random_seed = 470\n",
    "regularizations = [0.1, 1.0, 10.0, 100.0]\n",
    "gammas = [0.001, 0.01, 0.1, 1, 10]\n",
    "for regularization, gamma in product(regularizations, gammas):\n",
    "    svc_param_kwargs = {\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"C\": regularization,\n",
    "        \"gamma\": gamma,\n",
    "    }\n",
    "    # each call creates a \"run\" in MLflow and records metrics/artifacts about that run\n",
    "    create_run_svm_classify(\n",
    "        experiment_id,\n",
    "        train_x,\n",
    "        train_y,\n",
    "        test_x,\n",
    "        test_y,\n",
    "        random_seed,\n",
    "        svc_param_kwargs=svc_param_kwargs,\n",
    "        run_name=f\"C_{regularization}_gamma_{gamma}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"You created your first experiment!\")\n",
    "print(f\"Go to the Experiments UI and click on the {experiment_name} experiment to compare runs.\")\n",
    "print(\"You can also explore and share run artifacts (e.g. overview and confusion matrix).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
